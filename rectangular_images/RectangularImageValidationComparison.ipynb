{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenet Validation Techniques Compared - Square VS Rectangle VS TTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compare the different validation techniques on a pretrained resnet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validation_utils import sort_ar, chunks, map_idx2ar, ValDataset, SequentialIndexSampler, RectangularCropTfm, validate\n",
    "\n",
    "import sys, os, shutil, time, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Tiny ImageNet from https://tiny-imagenet.herokuapp.com/  \n",
    "`wget -qO- -O tmp.zip http://cs231n.stanford.edu/tiny-imagenet-200.zip && unzip tmp.zip && rm tmp.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_path = '/data/rliaw/explainability/' # Update the path to point to tiny-imagenet-200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "data = Path(imagenet_path + 'tiny-imagenet-200/train')\n",
    "workers = 7\n",
    "valdir = imagenet_path + 'tiny-imagenet-200/val/valdir'\n",
    "batch_size = 64\n",
    "fp16 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Added On) Build Correct Validation Directory File Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_path = os.path.join(imagenet_path, 'tiny-imagenet-200/val/val_annotations.txt')\n",
    "with open(_path) as f:\n",
    "    anns = [line.rstrip('\\n') for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "val_path = Path(valdir)\n",
    "if not os.path.exists(val_path):\n",
    "    os.mkdir(val_path)\n",
    "\n",
    "for ann in anns:\n",
    "    img_name, class_id, x0, y0, x1, y1 = ann.split()\n",
    "    img_path = os.path.join(imagenet_path, 'tiny-imagenet-200/val/images/{}'.format(img_name))\n",
    "    \n",
    "    new_path = os.path.join(imagenet_path, 'tiny-imagenet-200/val/valdir/{}'.format(class_id))\n",
    "    if not os.path.exists(new_path):\n",
    "        os.mkdir(new_path)\n",
    "    \n",
    "    copyfile(img_path, os.path.join(new_path, img_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create Image to Aspect ratio mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_ar_sorted = sort_ar(data, valdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Get untrained resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet\n",
    "model = resnet.resnet50(pretrained=False)\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "if fp16: model = model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, save_path, num_epochs=25, start_epoch=0):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, start_epoch + num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "            torch.save(model.state_dict(), \"{}/{}.pt\".format(save_path, epoch))\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "dataset_sizes = {'train': 100000,\n",
    "                 'val':    10000}\n",
    "\n",
    "trn_tfms = [transforms.ToTensor()]\n",
    "trn_img_folder = torchvision.datasets.ImageFolder(data, transforms.Compose(trn_tfms))\n",
    "val_img_folder = torchvision.datasets.ImageFolder(valdir, transforms.Compose(trn_tfms))\n",
    "\n",
    "dataloaders = {'train': torch.utils.data.DataLoader(trn_img_folder, shuffle=True),\n",
    "               'val':   torch.utils.data.DataLoader(val_img_folder, shuffle=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = model\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 200)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "import copy\n",
    "from torch import optim\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=2, save_path=\"/data/rliaw/explainability/temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = resnet.resnet50(pretrained=False).cuda()\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 200)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "import copy\n",
    "from torch import optim\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# Load model state from given epoch num\n",
    "epoch_num = 1\n",
    "model_ft.load_state_dict(torch.load(\"/data/rliaw/explainability/temp/{}.pt\".format(epoch_num)))\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5, start_epoch=epoch_num+1,\n",
    "                       save_path=\"/data/rliaw/explainability/temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/8\n",
      "----------\n",
      "train Loss: 3.4801 Acc: 0.2202\n",
      "val Loss: 13.8784 Acc: 0.0226\n",
      "\n",
      "Epoch 6/8\n",
      "----------\n",
      "train Loss: 3.1876 Acc: 0.2687\n",
      "val Loss: 8.8846 Acc: 0.0264\n",
      "\n",
      "Epoch 7/8\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model_ft = resnet.resnet50(pretrained=False).cuda()\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 200)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "import copy\n",
    "from torch import optim\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# Load model state from given epoch num\n",
    "epoch_num = 4\n",
    "model_ft.load_state_dict(torch.load(\"/data/rliaw/explainability/temp/{}.pt\".format(epoch_num)))\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=4, start_epoch=epoch_num+1,\n",
    "                       save_path=\"/data/rliaw/explainability/temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 2.6158 Acc: 0.3714\n",
      "val Loss: 14.3492 Acc: 0.0220\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 2.3324 Acc: 0.4264\n",
      "val Loss: 18.0368 Acc: 0.0189\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model_ft = resnet.resnet50(pretrained=False).cuda()\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 200)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "import copy\n",
    "from torch import optim\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# Load model state from given epoch num\n",
    "epoch_num = 7\n",
    "model_ft.load_state_dict(torch.load(\"/data/rliaw/explainability/temp/{}.pt\".format(epoch_num)))\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=7, start_epoch=epoch_num+1,\n",
    "                       save_path=\"/data/rliaw/explainability/temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 2.0186 Acc: 0.4898\n",
      "val Loss: 15.3556 Acc: 0.0251\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 1.7182 Acc: 0.5544\n",
      "val Loss: 20.9767 Acc: 0.0211\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 1.3902 Acc: 0.6292\n",
      "val Loss: 20.9082 Acc: 0.0214\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model_ft = resnet.resnet50(pretrained=False).cuda()\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 200)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "import copy\n",
    "from torch import optim\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# Load model state from given epoch num\n",
    "epoch_num = 9\n",
    "model_ft.load_state_dict(torch.load(\"/data/rliaw/explainability/temp/{}.pt\".format(epoch_num)))\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5, start_epoch=epoch_num+1,\n",
    "                       save_path=\"/data/rliaw/explainability/temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model_ft = resnet.resnet50(pretrained=False).cuda()\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 200)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "import copy\n",
    "from torch import optim\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# Load model state from given epoch num\n",
    "epoch_num = 12\n",
    "model_ft.load_state_dict(torch.load(\"/data/rliaw/explainability/temp/{}.pt\".format(epoch_num)))\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=3, start_epoch=epoch_num+1,\n",
    "                       save_path=\"/data/rliaw/explainability/temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global dataset settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_bs = 64\n",
    "target_size = 288\n",
    "\n",
    "idx_sorted, _ = zip(*idx_ar_sorted)\n",
    "idx2ar, ar_means = map_idx2ar(idx_ar_sorted, val_bs)\n",
    "val_sampler_ar = SequentialIndexSampler(idx_sorted)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "tensor_tfm = [transforms.ToTensor(), normalize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare different Validations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Square Validation Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize Image 1.14x -> Crop to target size (288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [100/157]\tTime 0.142 (0.170)\tLoss 34.9903 (33.6966)\tPrec@1 0.000 (0.031)\tPrec@5 0.000 (0.234)\n",
      "Test: [157/157]\tTime 0.892 (0.165)\tLoss 28.6202 (33.0846)\tPrec@1 0.000 (0.040)\tPrec@5 0.000 (0.220)\n",
      "Total Time:0.007190988888888889\t Top 5 Accuracy: 0.220\n",
      "\n",
      " * Prec@1 0.040 Prec@5 0.220\n"
     ]
    }
   ],
   "source": [
    "val_tfms = [transforms.Resize(int(target_size*1.14)), transforms.CenterCrop(target_size)] + tensor_tfm\n",
    "val_dataset = datasets.ImageFolder(valdir,  transforms.Compose(val_tfms))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=val_bs, shuffle=False,\n",
    "    num_workers=workers, pin_memory=True, sampler=val_sampler_ar)\n",
    "\n",
    "orig_prec5 = validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Fast.Ai Rectangular Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform validation with rectangular images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [100/157]\tTime 0.143 (0.152)\tLoss 34.9903 (33.6966)\tPrec@1 0.000 (0.031)\tPrec@5 0.000 (0.234)\n",
      "Test: [157/157]\tTime 0.040 (0.148)\tLoss 28.6202 (33.0846)\tPrec@1 0.000 (0.040)\tPrec@5 0.000 (0.220)\n",
      "Total Time:0.006467484999999999\t Top 5 Accuracy: 0.220\n",
      "\n",
      " * Prec@1 0.040 Prec@5 0.220\n"
     ]
    }
   ],
   "source": [
    "val_ar_tfms = [transforms.Resize(int(target_size*1.14)), RectangularCropTfm(idx2ar, target_size)]\n",
    "val_dataset_rect = ValDataset(valdir, val_ar_tfms+tensor_tfm)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset_rect, batch_size=val_bs, shuffle=False,\n",
    "    num_workers=workers, pin_memory=True, sampler=val_sampler_ar)\n",
    "\n",
    "rect_prec5 = validate(val_loader, model, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Square VS Rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_mean(array, size=10): return [np.array(c).mean() for c in chunks(array, 100)]\n",
    "batch_means = batch_mean(ar_means)\n",
    "rect_prec5_mean = batch_mean(rect_prec5)\n",
    "orig_prec5_mean = batch_mean(orig_prec5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalValidation</th>\n",
       "      <th>RectangularValidation</th>\n",
       "      <th>AR Mean</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.191886</td>\n",
       "      <td>0.191886</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OriginalValidation  RectangularValidation  AR Mean  Difference\n",
       "0            0.234375               0.234375      1.0         0.0\n",
       "1            0.191886               0.191886      1.0         0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'OriginalValidation': orig_prec5_mean, \n",
    "     'RectangularValidation': rect_prec5_mean, \n",
    "     'AR Mean': batch_means,\n",
    "     'Difference': np.array(rect_prec5_mean)-np.array(orig_prec5_mean)}\n",
    "df = pd.DataFrame(data=d); df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate with TTA (Test Time Augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 4 random crops + original validation image and averages the predictions together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_scale = 0.5\n",
    "trn_tfms = [\n",
    "        transforms.RandomResizedCrop(target_size, scale=(min_scale, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ] + tensor_tfm\n",
    "aug_dataset = datasets.ImageFolder(valdir, transforms.Compose(trn_tfms))\n",
    "\n",
    "val_tfms = [transforms.Resize(int(target_size*1.14)), transforms.CenterCrop(target_size)] + tensor_tfm\n",
    "val_dataset = datasets.ImageFolder(valdir,  transforms.Compose(val_tfms))\n",
    "\n",
    "aug_loader = torch.utils.data.DataLoader(\n",
    "    aug_dataset, batch_size=val_bs, shuffle=False,\n",
    "    num_workers=workers, pin_memory=True, sampler=val_sampler_ar)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=val_bs, shuffle=False,\n",
    "    num_workers=workers, pin_memory=True, sampler=val_sampler_ar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [100/157]\tTime 0.721 (0.756)\tLoss 34.3519 (32.7869)\tPrec@1 0.000 (0.016)\tPrec@5 0.000 (0.250)\n",
      "Test: [157/157]\tTime 0.198 (0.741)\tLoss 29.1596 (32.1386)\tPrec@1 0.000 (0.030)\tPrec@5 0.000 (0.200)\n",
      "Total Time:0.032309113888888887\t Top 5 Accuracy: 0.200\n",
      "\n",
      " * Prec@1 0.030 Prec@5 0.200\n"
     ]
    }
   ],
   "source": [
    "tta_prec5 = validate(val_loader, model, criterion, aug_loader=aug_loader, num_augmentations=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate with TTA and Rectangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 4 random crops + recangular validation image and averages the predictions together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [100/157]\tTime 0.724 (0.741)\tLoss 34.6764 (32.7518)\tPrec@1 0.000 (0.016)\tPrec@5 0.000 (0.250)\n",
      "Test: [157/157]\tTime 0.199 (0.731)\tLoss 28.8469 (32.1384)\tPrec@1 0.000 (0.030)\tPrec@5 0.000 (0.230)\n",
      "Total Time:0.03188365861111111\t Top 5 Accuracy: 0.230\n",
      "\n",
      " * Prec@1 0.030 Prec@5 0.230\n"
     ]
    }
   ],
   "source": [
    "min_scale = 0.5\n",
    "trn_tfms = [\n",
    "        transforms.RandomResizedCrop(target_size, scale=(min_scale, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ] + tensor_tfm\n",
    "aug_dataset = datasets.ImageFolder(valdir, transforms.Compose(trn_tfms))\n",
    "\n",
    "aug_loader = torch.utils.data.DataLoader(\n",
    "    aug_dataset, batch_size=val_bs, shuffle=False,\n",
    "    num_workers=workers, pin_memory=True, sampler=val_sampler_ar)\n",
    "\n",
    "val_ar_tfms = [transforms.Resize(int(target_size*1.14)), RectangularCropTfm(idx2ar, target_size)]\n",
    "val_dataset_rect = ValDataset(valdir, val_ar_tfms+tensor_tfm)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset_rect, batch_size=val_bs, shuffle=False,\n",
    "    num_workers=workers, pin_memory=True, sampler=val_sampler_ar)\n",
    "\n",
    "tta_rect_prec5 = validate(val_loader, model, criterion, aug_loader=aug_loader, num_augmentations=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing all the Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_mean(array, size=10): return [np.array(c).mean() for c in chunks(array, 100)]\n",
    "batch_means = batch_mean(ar_means)\n",
    "rect_prec5_mean = batch_mean(rect_prec5)\n",
    "orig_prec5_mean = batch_mean(orig_prec5)\n",
    "tta_prec5_mean = batch_mean(tta_prec5)\n",
    "tta_rect_prec5_mean = batch_mean(tta_rect_prec5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Validation</th>\n",
       "      <th>Rectangular Validation</th>\n",
       "      <th>TTA Validation</th>\n",
       "      <th>TTA + Rectangular Validation</th>\n",
       "      <th>AR Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.191886</td>\n",
       "      <td>0.191886</td>\n",
       "      <td>0.109649</td>\n",
       "      <td>0.191886</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Original Validation  Rectangular Validation  TTA Validation  \\\n",
       "0             0.234375                0.234375        0.250000   \n",
       "1             0.191886                0.191886        0.109649   \n",
       "\n",
       "   TTA + Rectangular Validation  AR Mean  \n",
       "0                      0.250000      1.0  \n",
       "1                      0.191886      1.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Original Validation': orig_prec5_mean, \n",
    "     'Rectangular Validation': rect_prec5_mean, \n",
    "     'TTA Validation': tta_prec5_mean, \n",
    "     'TTA + Rectangular Validation': tta_rect_prec5_mean, \n",
    "     'AR Mean': batch_means}\n",
    "df = pd.DataFrame(data=d); df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
